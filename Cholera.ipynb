{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age (in years)  Sex       Clinical symptoms - Profuse watery diarrhoea  \\\n",
      "0               NaN  NaN  (Rice water stools), Severe thirst and severe ...   \n",
      "1              35.0  0.0                                                  1   \n",
      "2              42.0  1.0                                                  1   \n",
      "3              29.0  1.0                                                  0   \n",
      "4              52.0  0.0                                                  0   \n",
      "5              48.0  1.0                                                  0   \n",
      "6              38.0  0.0                                                  1   \n",
      "7              24.0  0.0                                                  0   \n",
      "8              32.0  1.0                                                  1   \n",
      "9              33.0  1.0                                                  0   \n",
      "10             23.0  1.0                                                  1   \n",
      "11             35.0  0.0                                                  1   \n",
      "12             56.0  1.0                                                  1   \n",
      "13             24.0  0.0                                                  0   \n",
      "14             46.0  0.0                                                  0   \n",
      "15             31.0  1.0                                                  0   \n",
      "16             27.0  1.0                                                  1   \n",
      "17             40.0  1.0                                                  0   \n",
      "18             38.0  0.0                                                  1   \n",
      "19             23.0  1.0                                                  0   \n",
      "20             26.0  0.0                                                  1   \n",
      "21             20.0  1.0                                                  1   \n",
      "22             26.0  1.0                                                  1   \n",
      "23             30.0  0.0                                                  0   \n",
      "24             19.0  0.0                                                  0   \n",
      "25             48.0  1.0                                                  0   \n",
      "26             55.0  0.0                                                  1   \n",
      "27             57.0  0.0                                                  0   \n",
      "28             44.0  1.0                                                  1   \n",
      "29             21.0  1.0                                                  0   \n",
      "..              ...  ...                                                ...   \n",
      "281            35.0  0.0                                                  1   \n",
      "282            56.0  1.0                                                  0   \n",
      "283            24.0  0.0                                                  0   \n",
      "284            46.0  0.0                                                  0   \n",
      "285            31.0  1.0                                                  0   \n",
      "286            27.0  1.0                                                  0   \n",
      "287            40.0  1.0                                                  0   \n",
      "288            38.0  0.0                                                  1   \n",
      "289            23.0  1.0                                                  0   \n",
      "290            26.0  0.0                                                  1   \n",
      "291            20.0  1.0                                                  1   \n",
      "292            26.0  1.0                                                  1   \n",
      "293            30.0  0.0                                                  0   \n",
      "294            17.0  0.0                                                  0   \n",
      "295            48.0  1.0                                                  0   \n",
      "296            55.0  0.0                                                  0   \n",
      "297            57.0  0.0                                                  0   \n",
      "298            44.0  1.0                                                  1   \n",
      "299            21.0  1.0                                                  0   \n",
      "300            59.0  0.0                                                  1   \n",
      "301            23.0  1.0                                                  0   \n",
      "302            35.0  0.0                                                  1   \n",
      "303            56.0  1.0                                                  1   \n",
      "304            24.0  0.0                                                  1   \n",
      "305            46.0  0.0                                                  0   \n",
      "306            31.0  1.0                                                  1   \n",
      "307            27.0  1.0                                                  0   \n",
      "308            40.0  1.0                                                  0   \n",
      "309            38.0  0.0                                                  1   \n",
      "310            23.0  1.0                                                  0   \n",
      "\n",
      "    Dehydration Signs like loss of skin elasticity, sunken eyes Temperature  \\\n",
      "0                     dry and  bluish mucous membranes               in â—¦F    \n",
      "1                                                    1                 97.8   \n",
      "2                                                    1                   99   \n",
      "3                                                    0                   97   \n",
      "4                                                    0                 97.6   \n",
      "5                                                    0                 98.2   \n",
      "6                                                    1                 98.5   \n",
      "7                                                    0                 99.7   \n",
      "8                                                    1                100.7   \n",
      "9                                                    0                 97.2   \n",
      "10                                                   1                 99.6   \n",
      "11                                                   1                 97.8   \n",
      "12                                                   1                   99   \n",
      "13                                                   0                   97   \n",
      "14                                                   0                 97.6   \n",
      "15                                                   0                 98.2   \n",
      "16                                                   1                 98.5   \n",
      "17                                                   0                 99.7   \n",
      "18                                                   1                100.7   \n",
      "19                                                   0                 97.2   \n",
      "20                                                   1                 99.6   \n",
      "21                                                   1                 97.8   \n",
      "22                                                   1                   99   \n",
      "23                                                   0                   97   \n",
      "24                                                   0                 97.6   \n",
      "25                                                   0                 98.2   \n",
      "26                                                   1                 98.5   \n",
      "27                                                   0                 99.7   \n",
      "28                                                   1                100.7   \n",
      "29                                                   0                 97.2   \n",
      "..                                                 ...                  ...   \n",
      "281                                                  1                 97.8   \n",
      "282                                                  0                 97.2   \n",
      "283                                                  0                   97   \n",
      "284                                                  0                 97.6   \n",
      "285                                                  0                 98.2   \n",
      "286                                                  0                 97.2   \n",
      "287                                                  0                 99.7   \n",
      "288                                                  1                100.7   \n",
      "289                                                  0                 97.2   \n",
      "290                                                  1                 99.6   \n",
      "291                                                  1                 97.8   \n",
      "292                                                  1                   99   \n",
      "293                                                  0                   97   \n",
      "294                                                  0                 97.6   \n",
      "295                                                  0                 98.2   \n",
      "296                                                  0                 97.2   \n",
      "297                                                  0                 99.7   \n",
      "298                                                  1                100.7   \n",
      "299                                                  0                 97.2   \n",
      "300                                                  1                 99.6   \n",
      "301                                                  0                   97   \n",
      "302                                                  1                  105   \n",
      "303                                                  1                  105   \n",
      "304                                                  1                  105   \n",
      "305                                                  0                 97.2   \n",
      "306                                                  1                  105   \n",
      "307                                                  0                 97.2   \n",
      "308                                                  0                 97.2   \n",
      "309                                                  1                  105   \n",
      "310                                                  0                 97.2   \n",
      "\n",
      "    Systolic Blood Pressure Diastolic Blood Pressure   heart rate   target  \n",
      "0                     MM/Hg                    MM/Hg  in beats/min     NaN  \n",
      "1                       100                       60            92     1.0  \n",
      "2                        92                       56            88     1.0  \n",
      "3                       110                       60            86     0.0  \n",
      "4                       120                       70            98     0.0  \n",
      "5                       100                       60           102     0.0  \n",
      "6                        90                       70           100     1.0  \n",
      "7                       110                       80            78     0.0  \n",
      "8                       100                       70           106     1.0  \n",
      "9                       100                       50            84     0.0  \n",
      "10                       90                       66            90     1.0  \n",
      "11                      100                       60            92     1.0  \n",
      "12                       92                       56            88     1.0  \n",
      "13                      110                       60            86     0.0  \n",
      "14                      120                       70            98     0.0  \n",
      "15                      100                       60           102     0.0  \n",
      "16                       90                       70           100     1.0  \n",
      "17                      110                       80            78     0.0  \n",
      "18                      100                       70           106     1.0  \n",
      "19                      100                       50            84     0.0  \n",
      "20                       90                       66            90     1.0  \n",
      "21                      700                       60            92     1.0  \n",
      "22                       92                       56            88     1.0  \n",
      "23                      110                       60            86     0.0  \n",
      "24                      120                       70            98     0.0  \n",
      "25                      100                       60           102     0.0  \n",
      "26                       90                       70           100     1.0  \n",
      "27                      110                       80            78     0.0  \n",
      "28                      100                       70           106     1.0  \n",
      "29                      100                       50            84     0.0  \n",
      "..                      ...                      ...           ...     ...  \n",
      "281                     100                       60            92     1.0  \n",
      "282                     100                       70            84     0.0  \n",
      "283                     110                       60            86     0.0  \n",
      "284                     120                       70            98     0.0  \n",
      "285                     100                       60           102     0.0  \n",
      "286                     100                       70            84     0.0  \n",
      "287                     110                       80            78     0.0  \n",
      "288                     100                       70           106     1.0  \n",
      "289                     100                       70            84     0.0  \n",
      "290                      90                       66            90     1.0  \n",
      "291                     100                       60            92     1.0  \n",
      "292                      92                       56            88     1.0  \n",
      "293                     110                       60            86     0.0  \n",
      "294                     120                       70            98     0.0  \n",
      "295                     100                       60           102     0.0  \n",
      "296                     100                       70            84     0.0  \n",
      "297                     110                       80            78     0.0  \n",
      "298                     100                       70           106     1.0  \n",
      "299                     100                       50            84     0.0  \n",
      "300                      90                       66            90     1.0  \n",
      "301                     110                       70            82     0.0  \n",
      "302                      92                       64            84     1.0  \n",
      "303                      92                       64            84     1.0  \n",
      "304                      92                       64            84     1.0  \n",
      "305                     100                       70            84     0.0  \n",
      "306                      92                       64            84     1.0  \n",
      "307                     100                       70            84     0.0  \n",
      "308                     100                       70            84     0.0  \n",
      "309                      92                       64            84     1.0  \n",
      "310                     100                       70            84     0.0  \n",
      "\n",
      "[311 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel (r'data.xlsx')\n",
    "print (data)\n",
    "data=data.loc[2:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = data.loc[data['target']==1]\n",
    "negative = data.loc[data['target']==0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,0:8]\n",
    "Y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Using RandomForestClassifier Method\n",
      "Accuracy - 100.0\n",
      "Recall - 1.0\n",
      "Precision Score - 1.0\n",
      "Confusion matrix\n",
      "[[12  0]\n",
      " [ 0 13]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFC = RandomForestClassifier()\n",
    "RFC.fit(xtrain, ytrain)\n",
    "pred_rfc = RFC.predict(xtest)\n",
    "acc_rfc = metrics.accuracy_score(ytest, pred_rfc)*100\n",
    "joblib.dump(RFC, 'model_RFC.pkl')\n",
    "\n",
    "\n",
    "print('1. Using RandomForestClassifier Method')\n",
    "print('Accuracy - {}'.format(acc_rfc))\n",
    "print('Recall - {}'.format(metrics.recall_score(ytest, pred_rfc)))\n",
    "print('Precision Score - {}'.format(metrics.precision_score(ytest, pred_rfc)))\n",
    "print('Confusion matrix')\n",
    "print(metrics.confusion_matrix(ytest, pred_rfc))\n",
    "print('\\n')\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Using Gradient Boosting Method\n",
      "Accuracy - 100.0\n",
      "Recall - 1.0\n",
      "Precision Score - 1.0\n",
      "Confusion matrix\n",
      "[[12  0]\n",
      " [ 0 13]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GB = GradientBoostingClassifier()\n",
    "GB.fit(xtrain, ytrain)\n",
    "pred_gb = GB.predict(xtest)\n",
    "acc_gb = metrics.accuracy_score(ytest, pred_gb)*100\n",
    "joblib.dump(GB, 'model_GB.pkl')\n",
    "\n",
    "\n",
    "print('2. Using Gradient Boosting Method')\n",
    "print('Accuracy - {}'.format(acc_gb))\n",
    "print('Recall - {}'.format(metrics.recall_score(ytest, pred_gb)))\n",
    "print('Precision Score - {}'.format(metrics.precision_score(ytest, pred_gb)))\n",
    "print('Confusion matrix')\n",
    "print(metrics.confusion_matrix(ytest, pred_gb))\n",
    "print('\\n')\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Using Logistic Regression Method\n",
      "Accuracy - 100.0\n",
      "Recall - 1.0\n",
      "Precision Score - 1.0\n",
      "Confusion matrix\n",
      "[[12  0]\n",
      " [ 0 13]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression()\n",
    "LR.fit(xtrain, ytrain)\n",
    "pred_lr = LR.predict(xtest)\n",
    "acc_lr = metrics.accuracy_score(ytest, pred_lr)*100\n",
    "joblib.dump(LR, 'model.pkl')\n",
    "\n",
    "print('3. Using Logistic Regression Method')\n",
    "print('Accuracy - {}'.format(acc_lr))\n",
    "print('Recall - {}'.format(metrics.recall_score(ytest, pred_lr)))\n",
    "print('Precision Score - {}'.format(metrics.precision_score(ytest, pred_lr)))\n",
    "print('Confusion matrix')\n",
    "print(metrics.confusion_matrix(ytest, pred_lr))\n",
    "print('\\n')\n",
    "time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Using SVM Method\n",
      "Accuracy - 100.0\n",
      "Recall - 1.0\n",
      "Precision Score - 1.0\n",
      "Confusion matrix\n",
      "[[12  0]\n",
      " [ 0 13]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "SVM = svm.LinearSVC(loss='hinge')\n",
    "SVM.fit(xtrain, ytrain)\n",
    "pred_svm = SVM.predict(xtest)\n",
    "acc_svm = metrics.accuracy_score(ytest, pred_svm)*100\n",
    "joblib.dump(SVM, 'model_SVM.pkl')\n",
    "\n",
    "print('4. Using SVM Method')\n",
    "print('Accuracy - {}'.format(acc_svm))\n",
    "print('Recall - {}'.format(metrics.recall_score(ytest, pred_svm)))\n",
    "print('Precision Score - {}'.format(metrics.precision_score(ytest, pred_svm)))\n",
    "print('Confusion matrix')\n",
    "print(metrics.confusion_matrix(ytest, pred_svm))\n",
    "print('\\n')\n",
    "time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Using KNN Method\n",
      "Accuracy - 96.0\n",
      "Recall - 1.0\n",
      "Precision Score - 0.9285714285714286\n",
      "Confusion matrix\n",
      "[[11  1]\n",
      " [ 0 13]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier(n_neighbors=15)\n",
    "KNN.fit(xtrain, ytrain)\n",
    "pred_knn = KNN.predict(xtest)\n",
    "acc_knn = metrics.accuracy_score(ytest, pred_knn)*100\n",
    "joblib.dump(KNN, 'model_KNN.pkl')\n",
    "\n",
    "\n",
    "print('5. Using KNN Method')\n",
    "print('Accuracy - {}'.format(acc_knn))\n",
    "print('Recall - {}'.format(metrics.recall_score(ytest, pred_knn)))\n",
    "print('Precision Score - {}'.format(metrics.precision_score(ytest, pred_knn)))\n",
    "print('Confusion matrix')\n",
    "print(metrics.confusion_matrix(ytest, pred_knn))\n",
    "print('\\n')\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. Using Decision Tree Method\n",
      "Accuracy - 100.0\n",
      "Recall - 1.0\n",
      "Precision Score - 1.0\n",
      "Confusion matrix\n",
      "[[12  0]\n",
      " [ 0 13]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT = DecisionTreeClassifier(max_depth=10, random_state=101, max_features=None, min_samples_leaf=10)\n",
    "DT.fit(xtrain, ytrain)\n",
    "pred_DT = DT.predict(xtest)\n",
    "acc_DT = metrics.accuracy_score(ytest, pred_DT)*100\n",
    "joblib.dump(DT, 'model_DT.pkl')\n",
    "\n",
    "\n",
    "print('6. Using Decision Tree Method')\n",
    "print('Accuracy - {}'.format(acc_DT))\n",
    "print('Recall - {}'.format(metrics.recall_score(ytest, pred_DT)))\n",
    "print('Precision Score - {}'.format(metrics.precision_score(ytest, pred_DT)))\n",
    "print('Confusion matrix')\n",
    "print(metrics.confusion_matrix(ytest, pred_DT))\n",
    "print('\\n')\n",
    "time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8. Using MLP Method\n",
      "Accuracy - 100.0\n",
      "Recall - 1.0\n",
      "Precision Score - 1.0\n",
      "Confusion matrix\n",
      "[[12  0]\n",
      " [ 0 13]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "MLP = MLPClassifier(hidden_layer_sizes=(15,4,1))\n",
    "MLP.fit(xtrain, ytrain)\n",
    "pred_MLP = MLP.predict(xtest)\n",
    "acc_MLP = metrics.accuracy_score(ytest, pred_MLP)*100\n",
    "joblib.dump(MLP, 'model.pkl')\n",
    "\n",
    "print('8. Using MLP Method')\n",
    "print('Accuracy - {}'.format(acc_MLP))\n",
    "print('Recall - {}'.format(metrics.recall_score(ytest, pred_MLP)))\n",
    "print('Precision Score - {}'.format(metrics.precision_score(ytest, pred_MLP)))\n",
    "print('Confusion matrix')\n",
    "print(metrics.confusion_matrix(ytest, pred_MLP))\n",
    "print('\\n')\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Defining labels and data\n",
    "height = [acc_rfc, acc_gb, acc_lr, acc_svm , acc_knn, acc_DT, acc_MLP]\n",
    "bars = ('RF', 'GB', 'LR', 'SVM', 'KNN', 'DT', 'MLP')\n",
    "y_pos = np.arange(len(bars))\n",
    " \n",
    "# Create bars and choose color\n",
    "plt.bar(y_pos, height, color = (1.00, 0.65, 0.00, 1.0))\n",
    " \n",
    "# Add Title and Axis names\n",
    "plt.title('Comparision Study')\n",
    "plt.xlabel('Algorithms')\n",
    "plt.ylabel('Accuracy')\n",
    " \n",
    "# Limits for the Y axis\n",
    "plt.ylim(0,100) \n",
    "# Create names\n",
    "plt.xticks(y_pos, bars) \n",
    "#Save the graphic\n",
    "plt.savefig('Comparison_Study')\n",
    "# Show graphic\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
